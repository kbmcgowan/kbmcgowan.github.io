{"title":"Forced-alignment and segmentation of airflow data","markdown":{"yaml":{"title":"Forced-alignment and segmentation of airflow data","date":"2009-03-23 15:11:16","categories":"praat airflow htk","image":"images/praat.png"},"containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_hooks$set(eval = function(options) {\n  if (options$engine == \"bash\") {\n    options$eval <- FALSE\n  }\n  options\n})\n```\n\nAn airflow system like <a href=\"http://www.sqlab.fr/evaRootUK.htm\">the SQLab EVA2</a> used in our lab creates separate wav-like files for audio, oral airflow, and nasal airflow.  Usually we use a program like <a href=\"http://www.speech.kth.se/wavesurfer/\">wavesurfer</a> or <a href=\"http://www.fon.hum.uva.nl/praat/\">Praat</a> to view these files and extract our measurements.\n\nBut what if you want to extract measurements for all of the segments in a reasonably-sized corpus of continuous speech?  This can, of course, be done by hand but the process is tedious, labor-intensive, and inescapably subjective.\n This tutorial explains how to use Praat and HTK to segment audio recordings and use that segmentation to extract phone-level airflow data for an entire corpus.  The segmentation is unlikely to be as good as a trained linguist might achieve, but it's definitely faster and a very good starting point.  The corpus I'm working with is a set of recordings of the <a href=\"http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S1\">TIMIT</a> prompts I made for my doctoral candidacy qualifying project:  Modeling Airflow for Concatenative Speech Synthesis.\n\n**Solution**\n\n1. Convert the EVA2 files to WAV format.\n\nSQLab distribute a piece of Windows-only, closed-source software called <a href=\"http://www.lpl.univ-aix.fr/~lpldev/lpltools/\">RIFF Edit</a> for converting from their proprietary format to WAV format.  Works great on my Mac using <a href=\"http://www.codeweavers.com/products/\">CrossOver</a> which, I believe, is just a very nice version of <a href=\"http://www.winehq.org/\">wine</a>.\n\n\n2. Break the audio recordings up into separate files (one prompt/sentence per file)\nOf course there are many ways to do this.  Usually one would record each prompt separately so that the audio files are naturally in separate files.  The clumsy EVA2 system makes this arrangement difficult, though, so I used a TextGrid to mark each prompt on an interval tier.  This can be done automatically using Praat's \"Annotate --> To TextGrid (Silences)\" command (some clean-up is usually necessary, but it saves a lot of work).  Once the prompts are marked in the TextGrid I <a href=\"/stuff/assets/extract.praat\">run this Praat script that I did not write</a>.\n\n( As a quick aside, <a href=\"http://www.ling.upenn.edu/~kgorman/\">Kyle Gorman</a> has written a terrific little Python class for manipulating TextGrids --does exactly what you'd want in just exactly the way you'd probably expect. )</a>\n\n\n3. Now use the same TextGrid and script to extract prompts from the OAF (oral airflow) and NAF (nasal airflow) files.\n\nThis is the great strength of using something like Praat in the first place.  Be sure to check a random sample of your alignments to make sure everything worked, but I've never had a problem.\n\n\n4. Label all three files properly\n\nMy utterances are in a file called utts.data (identical to the file needed by Festival for voice creation) with the format:\n\n    (audio_0003 \"This was easy for us.\")\n    (audio_0004 \"Jane may earn more money by working hard.\")\n    (audio_0005 \"She is thinner than I am.\")\n    (audio_0006 \"Bright sunshine shimmers on the ocean.\")\n    (audio_0007 \"Nothing is as offensive as innocence.\")\n    (audio_0008 \"Why yell or worry over silly items?\")\n    (audio_0009 \"Where were you while we were away?\")\n\n&nbsp;\n\nAnd then I run the shell script <a href=\"/blog/assets/mkpf.sh\">mkpf.sh</a> to double check the audio and create the prompt files.\n\n```{bash, eval=FALSE, echo=T, engine=\"bash\"}\n\n#!/bin/bash\n\nexport UTTS=../utts.data\n\necho which file are we starting with [ 1 = first ]?\nread START;\n\nif [ \"$START\" == \"\" ]; then\n     START=1\nfi\n\nfor i in `ls a*.wav | sort -n -k1.2`; do\n    num=`printf \"%04d\" $START`\n\n    line=`grep \"audio_$num\" $UTTS`\n    prompt=`echo $line | awk -F\\\" '{print $2}'`\n    echo $line\n    afplay $i;\n    echo make $i $num [y] ?;\n\n    read ANSWER;\n\n    if [ \"$ANSWER\" == \"n\" ]; then\n        echo doing nothing\n    else\n        if [ \"$ANSWER\" == \"p\" ]; then\n            let \"START = START - 1\"\n            num=`printf \"%04d\" $START`\n\n            echo overwriting $i to $num ...\n        else\n            echo saving $i to $num ...\n        fi\n\n        cp $i audio_${num}.wav\n        cp oaf_$i oaf_${num}.wav\n        cp naf_$i naf_${num}.wav\n        echo $prompt > ${num}.txt\n        rm $i\n\n        let \"START = START + 1\"\n    fi\ndone\n\n```\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_hooks$set(eval = function(options) {\n  if (options$engine == \"bash\") {\n    options$eval <- FALSE\n  }\n  options\n})\n```\n\nAn airflow system like <a href=\"http://www.sqlab.fr/evaRootUK.htm\">the SQLab EVA2</a> used in our lab creates separate wav-like files for audio, oral airflow, and nasal airflow.  Usually we use a program like <a href=\"http://www.speech.kth.se/wavesurfer/\">wavesurfer</a> or <a href=\"http://www.fon.hum.uva.nl/praat/\">Praat</a> to view these files and extract our measurements.\n\nBut what if you want to extract measurements for all of the segments in a reasonably-sized corpus of continuous speech?  This can, of course, be done by hand but the process is tedious, labor-intensive, and inescapably subjective.\n This tutorial explains how to use Praat and HTK to segment audio recordings and use that segmentation to extract phone-level airflow data for an entire corpus.  The segmentation is unlikely to be as good as a trained linguist might achieve, but it's definitely faster and a very good starting point.  The corpus I'm working with is a set of recordings of the <a href=\"http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S1\">TIMIT</a> prompts I made for my doctoral candidacy qualifying project:  Modeling Airflow for Concatenative Speech Synthesis.\n\n**Solution**\n\n1. Convert the EVA2 files to WAV format.\n\nSQLab distribute a piece of Windows-only, closed-source software called <a href=\"http://www.lpl.univ-aix.fr/~lpldev/lpltools/\">RIFF Edit</a> for converting from their proprietary format to WAV format.  Works great on my Mac using <a href=\"http://www.codeweavers.com/products/\">CrossOver</a> which, I believe, is just a very nice version of <a href=\"http://www.winehq.org/\">wine</a>.\n\n\n2. Break the audio recordings up into separate files (one prompt/sentence per file)\nOf course there are many ways to do this.  Usually one would record each prompt separately so that the audio files are naturally in separate files.  The clumsy EVA2 system makes this arrangement difficult, though, so I used a TextGrid to mark each prompt on an interval tier.  This can be done automatically using Praat's \"Annotate --> To TextGrid (Silences)\" command (some clean-up is usually necessary, but it saves a lot of work).  Once the prompts are marked in the TextGrid I <a href=\"/stuff/assets/extract.praat\">run this Praat script that I did not write</a>.\n\n( As a quick aside, <a href=\"http://www.ling.upenn.edu/~kgorman/\">Kyle Gorman</a> has written a terrific little Python class for manipulating TextGrids --does exactly what you'd want in just exactly the way you'd probably expect. )</a>\n\n\n3. Now use the same TextGrid and script to extract prompts from the OAF (oral airflow) and NAF (nasal airflow) files.\n\nThis is the great strength of using something like Praat in the first place.  Be sure to check a random sample of your alignments to make sure everything worked, but I've never had a problem.\n\n\n4. Label all three files properly\n\nMy utterances are in a file called utts.data (identical to the file needed by Festival for voice creation) with the format:\n\n    (audio_0003 \"This was easy for us.\")\n    (audio_0004 \"Jane may earn more money by working hard.\")\n    (audio_0005 \"She is thinner than I am.\")\n    (audio_0006 \"Bright sunshine shimmers on the ocean.\")\n    (audio_0007 \"Nothing is as offensive as innocence.\")\n    (audio_0008 \"Why yell or worry over silly items?\")\n    (audio_0009 \"Where were you while we were away?\")\n\n&nbsp;\n\nAnd then I run the shell script <a href=\"/blog/assets/mkpf.sh\">mkpf.sh</a> to double check the audio and create the prompt files.\n\n```{bash, eval=FALSE, echo=T, engine=\"bash\"}\n\n#!/bin/bash\n\nexport UTTS=../utts.data\n\necho which file are we starting with [ 1 = first ]?\nread START;\n\nif [ \"$START\" == \"\" ]; then\n     START=1\nfi\n\nfor i in `ls a*.wav | sort -n -k1.2`; do\n    num=`printf \"%04d\" $START`\n\n    line=`grep \"audio_$num\" $UTTS`\n    prompt=`echo $line | awk -F\\\" '{print $2}'`\n    echo $line\n    afplay $i;\n    echo make $i $num [y] ?;\n\n    read ANSWER;\n\n    if [ \"$ANSWER\" == \"n\" ]; then\n        echo doing nothing\n    else\n        if [ \"$ANSWER\" == \"p\" ]; then\n            let \"START = START - 1\"\n            num=`printf \"%04d\" $START`\n\n            echo overwriting $i to $num ...\n        else\n            echo saving $i to $num ...\n        fi\n\n        cp $i audio_${num}.wav\n        cp oaf_$i oaf_${num}.wav\n        cp naf_$i naf_${num}.wav\n        echo $prompt > ${num}.txt\n        rm $i\n\n        let \"START = START + 1\"\n    fi\ndone\n\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":false,"output-file":"2009-03-23-align.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","theme":["journal","../../yeti-colors.scss"],"fontsize":"1.1em","title-block-banner":false,"title":"Forced-alignment and segmentation of airflow data","date":"2009-03-23 15:11:16","categories":"praat airflow htk","image":"images/praat.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}